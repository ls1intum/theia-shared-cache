{
  "annotations": {
    "list": []
  },
  "editable": true,
  "fiscalYearStartMonth": 0,
  "graphTooltip": 1,
  "links": [],
  "panels": [
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 0 },
      "id": 100,
      "title": "Cache Server",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "red", "value": null },
              { "color": "orange", "value": 0.5 },
              { "color": "yellow", "value": 0.7 },
              { "color": "green", "value": 0.85 }
            ]
          },
          "unit": "percentunit",
          "min": 0,
          "max": 1
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 6, "x": 0, "y": 1 },
      "id": 1,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["lastNotNull"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "title": "Cache Hit Rate",
      "description": "Percentage of cache lookups that found a cached result. Below 50% means the cache is barely helping. 70-90% is healthy. A sudden drop means build keys changed.",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "rate(gradle_cache_cache_hits[5m]) / (rate(gradle_cache_cache_hits[5m]) + rate(gradle_cache_cache_misses[5m]))",
          "legendFormat": "Hit Rate",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisBorderShow": false,
            "axisLabel": "req/s",
            "drawStyle": "line",
            "fillOpacity": 20,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "mode": "none" }
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 9, "x": 6, "y": 1 },
      "id": 2,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Request Rate by Method",
      "description": "Traffic pattern: GET=download, PUT=upload, HEAD=existence check. High PUT with few GETs means nobody reads the cache. Spikes correlate with CI runs.",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "sum by (method) (rate(gradle_cache_requests_total[5m]))",
          "legendFormat": "{{method}}",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisBorderShow": false,
            "axisLabel": "",
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "mode": "none" }
          },
          "unit": "s"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 9, "x": 15, "y": 1 },
      "id": 3,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Request Latency",
      "description": "Response time percentiles. Under 10ms is normal for Redis-backed cache. Spikes during PUTs indicate large artifacts. Gradual increase means Redis memory pressure.",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "histogram_quantile(0.50, sum by (le) (rate(gradle_cache_request_duration_seconds_bucket[5m])))",
          "legendFormat": "p50",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "histogram_quantile(0.95, sum by (le) (rate(gradle_cache_request_duration_seconds_bucket[5m])))",
          "legendFormat": "p95",
          "refId": "B"
        },
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "histogram_quantile(0.99, sum by (le) (rate(gradle_cache_request_duration_seconds_bucket[5m])))",
          "legendFormat": "p99",
          "refId": "C"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisBorderShow": false,
            "axisLabel": "req/s",
            "drawStyle": "line",
            "fillOpacity": 30,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "mode": "none" }
          },
          "unit": "reqps"
        },
        "overrides": [
          {
            "matcher": { "id": "byName", "options": "Hits" },
            "properties": [{ "id": "color", "value": { "fixedColor": "green", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "Misses" },
            "properties": [{ "id": "color", "value": { "fixedColor": "red", "mode": "fixed" } }]
          }
        ]
      },
      "gridPos": { "h": 6, "w": 12, "x": 0, "y": 7 },
      "id": 4,
      "options": {
        "legend": { "calcs": ["sum"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Cache Hits vs Misses",
      "description": "Green=hits (served from cache), Red=misses (Gradle had to rebuild). The ratio between these is your hit rate. Ideally green dominates.",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "rate(gradle_cache_cache_hits_total[5m])",
          "legendFormat": "Hits",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "rate(gradle_cache_cache_misses_total[5m])",
          "legendFormat": "Misses",
          "refId": "B"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "custom": {
            "axisBorderShow": false,
            "drawStyle": "line",
            "fillOpacity": 30,
            "lineWidth": 2,
            "stacking": { "mode": "none" }
          },
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 0.01 },
              { "color": "red", "value": 0.05 }
            ]
          },
          "unit": "reqps"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 12, "x": 12, "y": 7 },
      "id": 5,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "single", "sort": "none" }
      },
      "title": "Server Errors (5xx)",
      "description": "Rate of internal server errors. Should be zero. Any non-zero means Redis is unreachable or there's a bug. Investigate immediately — errors slow down every Gradle build.",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "sum(rate(gradle_cache_requests_total{status=~\"5..\"}[5m]))",
          "legendFormat": "5xx errors",
          "refId": "A"
        }
      ]
    },
    {
      "collapsed": false,
      "gridPos": { "h": 1, "w": 24, "x": 0, "y": 13 },
      "id": 200,
      "title": "Redis",
      "type": "row"
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "green", "value": null },
              { "color": "yellow", "value": 536870912 },
              { "color": "red", "value": 858993459 }
            ]
          },
          "unit": "decbytes"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 6, "x": 0, "y": 14 },
      "id": 6,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["lastNotNull"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "title": "Redis Memory Used",
      "description": "How much RAM Redis is consuming. Approaching your container limit (1-2Gi) means risk of OOM kill. Action: increase limit or add eviction policy (maxmemory-policy allkeys-lru).",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "redis_memory_used_bytes",
          "legendFormat": "Memory",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "thresholds" },
          "mappings": [],
          "thresholds": {
            "mode": "absolute",
            "steps": [
              { "color": "blue", "value": null }
            ]
          },
          "unit": "short"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 6, "x": 6, "y": 14 },
      "id": 7,
      "options": {
        "colorMode": "background",
        "graphMode": "area",
        "justifyMode": "auto",
        "orientation": "auto",
        "reduceOptions": {
          "calcs": ["lastNotNull"],
          "fields": "",
          "values": false
        },
        "textMode": "auto"
      },
      "title": "Cached Entries",
      "description": "Total keys in Redis. Combined with memory, gives average entry size (memory / keys). Zero after restart is expected with no persistence.",
      "type": "stat",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "redis_db_keys{db=\"db0\"}",
          "legendFormat": "Keys",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisBorderShow": false,
            "drawStyle": "line",
            "fillOpacity": 20,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "mode": "none" }
          },
          "unit": "decbytes"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 12, "x": 12, "y": 14 },
      "id": 8,
      "options": {
        "legend": { "calcs": ["mean", "lastNotNull", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "single", "sort": "none" }
      },
      "title": "Redis Memory Over Time",
      "description": "Memory trend. Steady growth = cache filling up. Sawtooth (up then drop) = pod crashing and restarting. Flat = cache is stable or nobody is writing.",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "redis_memory_used_bytes",
          "legendFormat": "Used",
          "refId": "A"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisBorderShow": false,
            "axisLabel": "ops/s",
            "drawStyle": "line",
            "fillOpacity": 20,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "mode": "none" }
          },
          "unit": "ops"
        },
        "overrides": [
          {
            "matcher": { "id": "byName", "options": "Hits" },
            "properties": [{ "id": "color", "value": { "fixedColor": "green", "mode": "fixed" } }]
          },
          {
            "matcher": { "id": "byName", "options": "Misses" },
            "properties": [{ "id": "color", "value": { "fixedColor": "orange", "mode": "fixed" } }]
          }
        ]
      },
      "gridPos": { "h": 6, "w": 12, "x": 0, "y": 20 },
      "id": 9,
      "options": {
        "legend": { "calcs": ["sum"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "multi", "sort": "desc" }
      },
      "title": "Redis Keyspace Hits vs Misses",
      "description": "Redis-level hit/miss. Confirms app-level metrics. High misses here + high app misses = entries truly don't exist (build config issue, not Redis issue).",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "rate(redis_keyspace_hits_total[5m])",
          "legendFormat": "Hits",
          "refId": "A"
        },
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "rate(redis_keyspace_misses_total[5m])",
          "legendFormat": "Misses",
          "refId": "B"
        }
      ]
    },
    {
      "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
      "fieldConfig": {
        "defaults": {
          "color": { "mode": "palette-classic" },
          "custom": {
            "axisBorderShow": false,
            "axisLabel": "ops/s",
            "drawStyle": "line",
            "fillOpacity": 10,
            "lineWidth": 2,
            "pointSize": 5,
            "showPoints": "auto",
            "stacking": { "mode": "none" }
          },
          "unit": "ops"
        },
        "overrides": []
      },
      "gridPos": { "h": 6, "w": 12, "x": 12, "y": 20 },
      "id": 10,
      "options": {
        "legend": { "calcs": ["mean", "max"], "displayMode": "table", "placement": "bottom" },
        "tooltip": { "mode": "single", "sort": "none" }
      },
      "title": "Redis Commands/sec",
      "description": "Total Redis operations per second. Shows overall load on Redis. Redis handles ~100k ops/sec easily — if this approaches that, you have a scaling problem (unlikely for a build cache).",
      "type": "timeseries",
      "targets": [
        {
          "datasource": { "type": "prometheus", "uid": "PBFA97CFB590B2093" },
          "expr": "rate(redis_commands_processed_total[5m])",
          "legendFormat": "Commands/s",
          "refId": "A"
        }
      ]
    }
  ],
  "schemaVersion": 39,
  "tags": ["gradle", "cache", "redis"],
  "templating": { "list": [] },
  "time": { "from": "now-1h", "to": "now" },
  "timepicker": {},
  "timezone": "browser",
  "title": "Gradle Build Cache",
  "uid": "gradle-build-cache",
  "version": 1,
  "refresh": "10s"
}
